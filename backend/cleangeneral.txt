Cleaned_Ans
"Data Science is a combination of algorithms, tools, and machine learning technique which helps you to find common hidden patterns from the given raw data."
Logistic Regression is also called as the logit model It is a method to forecast the binary outcome from a linear combination of predictor variables.
"In the sampling process, there are three types of biases which are Selection bias Under coverage bias Survivorship bias."
A decision tree is a popular supervised machine learning algorithm It is mainly used for Regression and Classification It allows breaks down a dataset into smaller subsets The decision tree can able to handle both categorical and numerical data.
"Three disadvantages of the linear model are The assumption of linearity of the errors, You can t use this model for binary or count outcomes, There are plenty of overfitting problems that it can t solve."
"Resampling is done in below given cases Estimating the accuracy of sample statistics by drawing randomly with replacement from a set of the data point or using as subsets of accessible data , Substituting labels on data points when performing necessary tests, Validating models by using random subsets."
"libraries in Python used for Data Analysis and Scientific Computations are SciPy, Pandas, Matplotlib, NumPy, SciKit, Seaborn."
The power analysis is an integral part of the experimental design It helps you to determine the sample size requires to find out the effect of a given size from a cause with a specific level of assurance It also allows you to deploy a particular probability in a sample size constraint.
"Collaborative filtering used to search for correct patterns by collaborating viewpoints, multiple data sources, and various agents."
Bias is an error introduced in your model because of the oversimplification of a machine learning algorithm It can lead to underfitting.
The Naive Bayes Algorithm model is based on the Bayes Theorem It describes the probability of an event It is based on prior knowledge of conditions which might be related to that specific event.
Linear regression is a statistical programming method where the score of a variable A is predicted from the score of a second variable B B is referred to as the predictor variable and A as the criterion variable.
"AB testing used to conduct random experiments with two variables, A and B The goal of this testing method is to find out changes to a web page to maximize or increase the outcome of a strategy."
The ensemble is a method of combining a diverse set of learners together to improvise on the stability and predictive power of the model Two types of Ensemble learning methods are Bagging method helps you to implement similar learners on small sample populations It helps you to make nearer predictions Boosting is an iterative method which allows you to adjust the weight of an observation depends upon the last classification Boosting decreases the bias error and helps you to build strong predictive models.
"Eigenvectors are for understanding linear transformations Data scientist need to calculate the eigenvectors for a covariance matrix or correlation Eigenvalues are the directions along using specific linear transformation acts by compressing, flipping, or stretching."
"Cross validation is a validation technique for evaluating how the outcomes of statistical analysis will generalize for an Independent dataset This method is used in backgrounds where the objective is forecast, and one needs to estimate how accurately a model will accomplish."
"The following are important steps involved in an analytics project Understand the Business problem, Explore the data and study it carefully, Prepare the data for modeling by finding missing values and transforming variables, Start running the model and analyze the Big data result, Validate the model with new data set, Implement the model and track the result to analyze the performance of the model for a specific period."
Artificial Neural networks ANN are a special set of algorithms that have revolutionized machine learning It helps you to adapt according to changing input So the network generates the best possible result without redesigning the output criteria.
Back propagation is the essence of neural net training It is the method of tuning the weights of a neural net depend upon the error rate obtained in the previous epoch Proper tuning of the helps you to reduce error rates and to make the model reliable by increasing its generalization.
Random forest is a machine learning method which helps you to perform all types of regression and classification tasks It is also used for treating missing values and outlier values.
K means clustering is an important unsupervised learning method It is the technique of classifying data using a certain set of clusters which is called K clusters It is deployed for grouping to find out the similarity in the data.
"Data Scientists need to do slicing data to extract valuable insights that a data analyst can apply to real world business scenarios The main difference between the two is that the data scientists have more technical knowledge then business analyst Moreover,they don t need an understanding of the business required for data visualization."
"When you conduct a hypothesis test in statistics, a p value allows you to determine the strength of your results It is a numerical number between 0 and 1 Based on the value it will help you to denote the strength of the specific result."
"You can collect social media data using Facebook, twitter, Instagram s API sFor example, for the tweeter, we can construct a feature from each tweet like tweeted date, retweets, list of follower, etc Then you can use a multivariate time series model to predict the weather condition."
A normal distribution is a set of a continuous variable spread across a normal curve or in the shape of a bell curve You can consider it as a continuous probability distribution which is useful in statistics It is useful to analyze the variables and their relationships when we are using the normal distribution curve.
"Python will more suitable for text analytics as it consists of a rich library known as pandas It allows you to use high level data analysis tools and data structures, while R doesn t offer this feature."
"Statistics help Data scientist to get a better idea of customer s expectation Using the statistic method Data Scientists can get knowledge regarding consumer interest, behavior, engagement, retention, etc It also helps you to build powerful data models to validate certain inferences and predictions."
"Deep Learning Frameworks Pytorch, Microsoft Cognitive Toolkit, TensorFlow, Caffe, Chainer, Keras."
Boltzmann machines is a simple learning algorithm It helps you to discover those features that represent complex regularities in the training data This algorithm allows you to optimize the weights and the quantity for the given problem.
"Dirty data often leads to the incorrect inside, which can damage the prospect of any organization For example, if you want to run a targeted marketing campaign However, our data incorrectly tell you that a specific product will be in demand with your target audience the campaign will fail."
Skewed distribution occurs when if data is distributed on any one side of the plot whereas uniform distribution is identified when the data is spread is equal in the range.
Underfitting occurs when a statistical model or machine learning algorithm not able to capture the underlying trend of the data.
"Reinforcement Learning is a learning mechanism about how to map situations to actions The end result should help you to increase the binary reward signal In this method, a learner is not told which action to take but instead must discover which action offers a maximum reward As this method based on the reward penalty mechanism."
"commonly used algorithm by Data scientist are Linear regression, Logistic regression, Random Forest, KNN."
"Precision is the most commonly used error metric is n classification mechanism Its range is from 0 to 1, where 1 represents 100 ."
"An analysis which is applied to none attribute at a time is known as univariate analysis Boxplot is widely used, univariate model."
"A cluster sampling method is used when it is challenging to study the target population spread across, and simple random sampling can t be applied."
A Validation set mostly considered as a part of the training set as it is used for parameter selection which helps you to avoid overfitting of the model being built While a Test Set is used for testing or evaluating the performance of a trained machine learning model.
The binomial distribution contains the probabilities of every possible success on N trials for independent events that have a probability of of occurring.
"Normal distribution equally distributed as such the mean, median and mode are equal."
"Following methods of variable selection you can use Remove the correlated variables before selecting important variables, Use linear regression and select variables which depend on that p values, Use Backward, Forward Selection, and Stepwise Selection, Use Xgboost, Random Forest, and plot variable importance chart, Measure information gain for the given set of features and select top n features accordingly."
we can use analysis of covariance technique to capture the association between continuous and categorical variables.
"Data science applications are frequently used in healthcare, marketing, banking and finance, and policy work."
"Data Scientists are bigdata wranglers, gathering and analyzing large sets of structured and unstructured data ,Datascientist s role combines computer science, statistics, and mathematics."
