Cleaned_Ans
" machine learning is a branch of computer science which deals with system programming in order to automatically learn and improve with experience for example robots are programed so that they can perform the task based on data they gather from sensors it automatically learns programs from data."
"machine learning is a branch of computer science which deals with system programming in order to automatically learn and improve with experience and Types of machine learning are supervised and unsupervised."

"machine learning relates with the study, design and development of the algorithms that give computers the capability to learn without being explicitly programmed."

"while, data mining can be defined as the process in which the unstructured data tries to extract knowledge or unknown interesting patterns."
"In machine learning, when a statistical model describes random error or noise instead of underlying relationship overfitting occurs when a model is excessively complex, overfitting is normally observed, because of having too many parameters with respect to the number of training data types."
"the possibility of overfitting exists as the criteria used for training the model is not the same as the criteria used to judge the efficacy of a model by using a lot of data overfitting can be avoided, overfitting happens relatively as you have a small dataset, and you try to learn from it but if you have a small database and you are forced to come with a model based on that in such situation, you can use a technique known as cross validation."
"Cross validation method , the dataset splits into two section, testing and training datasets, the testing dataset will only test the model while, in training dataset, the datapoints will come up with the model ,in this technique, a model is usually given a dataset of a known data on which training training data set is run and a dataset of unknown data against which the model is tested the idea of cross validation is to define a dataset to test the model in the training phase."
"the inductive machine learning involves the process of learning by examples, where a system, from a set of observed instances tries to induce a general rule."

"in various areas of information science like machine learning, a set of data is used to discover the potentially predictive relationship known as training set training set is an examples given to the learner, while test set is used to test the accuracy of the hypotheses generated by the learner, and it is the set of example held back from the learner training set are distinct from test set."


"in machine learning, perceptron is a supervised learning algorithm for binary classifiers where a binary classifier is a deciding function of whether an input represents a vector or a number."
"bayesian logic program consists of two components the first component is a logical one it consists of a set of bayesian clauses, which captures the qualitative structure of the domain the second component is a quantitative one, it encodes the quantitative information about the domain."
bayesian network is used to represent the graphical model for probability relationship among a set of variables instance based learning algorithm is also referred as lazy learning algorithm as they delay the induction or generalization process until classification is performed.
this process is known as ensemble learning.
"ensemble learning is used to improve the classification, prediction, function approximation etc of a model ensemble learning is used when you build component classifiers that are more accurate and independent from each other the two paradigms of ensemble methods are sequential ensemble methods parallel ensemble methods the general principle of an ensemble method is to combine the predictions of several models built with a given learning algorithm in order to improve robustness over a single model."
bagging is a method in ensemble for improving unstable estimation or classification schemes while boosting method are used sequentially to reduce the bias of the combined model boosting and bagging both can reduce errors by reducing the variance term.
the expected error of a learning algorithm can be decomposed into bias and variance.
bias term measures how closely the average classifier produced by the learning algorithm matches the target function the variance term measures how much the learning algorithm s prediction fluctuates for different training sets.
incremental learning method is the ability of an algorithm to learn from new data that may be available after classifier has already been generated from already available dataset.
"pca principal components analysis , kpca kernel based principal component analysis and ica independent component analysis are important feature extraction techniques used for dimensionality reduction."
support vector machines SVM are supervised learning algorithms used for classification and regression analysis using hyperplane.
the important components of relational evaluation techniques are data acquisition ground truth acquisition cross validation technique query type scoring metric significance test the different methods to solve sequential supervised learning problems are sliding window methods recurrent sliding windows hidden markow models maximum entropy markow models conditional random fields graph transformer networks the areas in robotics and information processing where sequential prediction problem arises are imitation learning structured prediction model based reinforcement learning statistical learning techniques allow learning a function or predictor from a set of observed data that can make predictions about unseen or future data these techniques provide guarantees on the performance of the learned predictor on the future unseen data based on a statistical assumption on the data generating process.
pac probably approximately correct learning is a learning framework that has been introduced to analyze learning algorithms and their statistical efficiency.
sequence prediction sequence generation sequence recognition sequential decision sequence learning is a method of teaching and learning in a logical manner.

"assumption of linear regression are ,1 Linear relationship There exists a linear relationship between the independent variable x and the dependent variable y ,2 Independence The residuals are independent In particular there is no correlation between consecutive residuals in time series data, 3 Homoscedasticity The residuals have constant variance at every level of x ,4 Normality The residuals of the model are normally distributed."

Underfitting is an issue when we have a low error in both the training set and the testing set Few algorithms work better for interpretations but fail for better predictions."
"Logistic Regression is also called as the logit model It is a method to forecast the binary outcome from a linear combination of predictor variables."

"A decision tree is a popular supervised machine learning algorithm It is mainly used for Regression and Classification It allows breaks down a dataset into smaller subsets The decision tree can able to handle both categorical and numerical data."

"linear regression is a statistical method that allows us to summarize and study relationships between continuous (quantitative) variables."
"assumptions of linear regression are:,1- Linear relationship: There exists a linear relationship between the independent variable x and the dependent variable y ,2- Independence: The residuals are independent In particular there is no correlation between consecutive residuals in time series data, 3- Homoscedasticity: The residuals have constant variance at every level of x ,4- Normality: The residuals of the model are normally distributed."
"Random forest is a machine learning method which helps you to perform all types of regression and classification tasks It is also used for treating missing values and outlier values."
"K means clustering is an important unsupervised learning method It is the technique of classifying data using a certain set of clusters which is called K clusters It is deployed for grouping to find out the similarity in the data."

"Difference between  deep learning and machine learning :- ML is all about algorithms which are used to parse data, learn from that data, and then apply whatever they have learned to make informed decisions Deep learning is a part of machine learning, which is inspired by the structure of the human brain and is particularly useful in feature detection."